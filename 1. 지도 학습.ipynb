{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "57bd6a52",
   "metadata": {},
   "source": [
    "# 데이터마이닝\n",
    "## 1. 지도학습\n",
    "### 1. 의사결정나무: CART, C5.0, C4.5, CHAID, 분리기준 (카이제곱통계량 p값, 지니 지수, 엔트로피 지수, F통계량, 분산의 감소량), 가지치기\n",
    "### 2. 앙상블분석: 배깅, 부스팅(Adaboost), 랜덤포레스트, 스태킹, 엑스트라트리, 에이다부스트\n",
    "### 3. 인공신경망\n",
    "    - 활성화함수(계단함수, 부호함수, 시그모이드 함수, relu함수, softmax 함수)\n",
    "    - 다층퍼셉트론\n",
    "    - ANN, DNN, CNN, RNN, GAN(InfoGAN, CycleGAN), RBM, DBN\n",
    "    - MLP-CNN-RNN 구현 및 비교\n",
    "    - ResNet, DenseNet\n",
    "    - AutoEncoder, VAE, DQN\n",
    "    - 진화 학습 (유전 알고리즘)\n",
    "    - 강화학습 (마르코프 결정과정)\n",
    "    - 대칭가중치와 심층신뢰 네트워크\n",
    "### 4. 회귀분석\n",
    "    - 가정검토(선형성, 등분산성-잔차도, 정규성-히스토그램/QQplot/Shapiro-wilk, 오차항의 독립성-더빈왓슨검정)\n",
    "    - 단순선형회귀분석(회귀계수 검정, 결정계수 계산-SST/SSR/SSE, 회귀직선의 적합도 검토)\n",
    "    - 다중선형회귀분석(회귀계수 검정, 회귀식, 결정계수 계산, 모형의 통계적 유의성, 교호작용, 다중공선성-PCA회귀, VIF 상위변수 제거)\n",
    "    - 다항회귀분석\n",
    "    - 스플라인 회귀\n",
    "    - 로지스틱 회귀\n",
    "    - 최적회귀방정식(전진선택법, 후진제거법, 단계적선택법 - AIC/BIC)\n",
    "    - 정규화 선형회귀 Regularized Linear Regression (Ridge회귀, Lasso회귀, Elastic Net 회귀)\n",
    "    - 일반화 선형회귀 Generalized Linear Regression\n",
    "    - 회귀분석의 기울기에 영향을 주는 영향점 진단: Cook's Distance, DFBETAS, DFFITS, Leverage H\n",
    "    - 변수 선택의 기준: 결정계수, Mallow's Cp, AIC/BIC\n",
    "### 5. 최근접 이웃법 (KNN), 가우시안 혼합모델\n",
    "### 6. 베이지안 분류\n",
    "### 7. SVM\n",
    "### 8. 판별분석\n",
    "### 9. 사례기반 추론 (Case based reasoning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "799571e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82cb1554",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('/Users/benny/Desktop/datascience/heart.csv')\n",
    "df_dummy = pd.get_dummies(df)\n",
    "X = df_dummy.drop('HeartDisease', axis=1)\n",
    "y = df_dummy['HeartDisease']\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train_clf, X_test_clf, y_train_clf, y_test_clf = train_test_split(X, y, stratify=y, test_size=0.2, random_state=1993)\n",
    "print(X_train_clf.shape, X_test_clf.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b2a9d52",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_boston\n",
    "df = load_boston()\n",
    "X = pd.DataFrame(df['data'], columns=df['feature_names'])\n",
    "y = pd.Series(df['target'], name='MEDV')\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train_reg, X_test_reg, y_train_reg, y_test_reg = train_test_split(X, y, test_size=0.2, random_state=1993)\n",
    "print(X_train_reg.shape, X_test_reg.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "364d3b66",
   "metadata": {},
   "source": [
    "### k-최근접 이웃 (k-NN, k-Nearest Neighbors) - 하이퍼 파라미터 찾기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69c2a3db",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5aef7cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator = KNeighborsClassifier()\n",
    "\n",
    "param_grid = {'n_neighbors':[1,2,3,4,5], 'metric':['minkowski','manhattan','euclidean'], 'weights':['uniform','distance']}\n",
    "\n",
    "grid = GridSearchCV(estimator, param_grid=param_grid) \n",
    "#grid = GridSearchCV(estimator, param_grid=param_grid, cv=3, scoring='accuracy') #디폴트로 cv=3, 분류에서 디폴트로 scoring='accuracy'\n",
    "\n",
    "grid.fit(X_train_clf, y_train_clf)\n",
    "\n",
    "print(grid.best_score_)\n",
    "print(grid.best_params_)\n",
    "df = pd.DataFrame(grid.cv_results_)\n",
    "print(df)\n",
    "#print(df.sort_values(by='param_n_neighbors'))\n",
    "#print(df.sort_values(by='param_n_neighbors', ascending=0))\n",
    "#print(df.sort_values(by='rank_test_score'))\n",
    "\n",
    "estimator = grid.best_estimator_\n",
    "\n",
    "# y_pred = estimator.decision_function(X_train_clf)[:2]\n",
    "y_prob = estimator.predict_proba(X_train_clf[:2]) #predict_proba is not available when  probability=False\n",
    "y_predict = estimator.predict(X_train_clf[:2])\n",
    "print(y_prob, '\\n', y_predict)\n",
    "\n",
    "score = grid.score(X_test_clf, y_test_clf)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "636fdff7",
   "metadata": {},
   "source": [
    "### k-최근접 이웃 (k-NN, k-Nearest Neighbors) - 회귀 - 하이퍼 파라미터 찾기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5ee830c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "estimator = KNeighborsRegressor()\n",
    "\n",
    "param_grid = {'n_neighbors':[1,2,3,4,5], 'metric':['minkowski','manhattan','euclidean'], 'weights':['uniform','distance']}\n",
    "\n",
    "grid = GridSearchCV(estimator, param_grid=param_grid) \n",
    "#grid = GridSearchCV(estimator, param_grid=param_grid, cv=3, scoring='r2') #디폴트로 cv=3, 회귀에서 디폴트로 scoring='r2'\n",
    "\n",
    "grid.fit(X_train_reg, y_train_reg)\n",
    "\n",
    "print(grid.best_score_)\n",
    "print(grid.best_params_)\n",
    "df = pd.DataFrame(grid.cv_results_)\n",
    "print(df)\n",
    "#print(df.sort_values(by='param_n_neighbors'))\n",
    "#print(df.sort_values(by='param_n_neighbors', ascending=0))\n",
    "#print(df.sort_values(by='rank_test_score'))\n",
    "\n",
    "estimator = grid.best_estimator_\n",
    "'''\n",
    "#estimator = KNeighborsRegressor(**grid.best_params_)\n",
    "estimator = KNeighborsRegressor()\n",
    "estimator.set_params(**grid.best_params_)\n",
    "\n",
    "estimator.fit(x_data, y_data)\n",
    "'''\n",
    "\n",
    "y_pred = estimator.predict(X_train_reg[:2])\n",
    "print(y_pred)\n",
    "\n",
    "score = grid.score(X_test_reg, y_test_reg)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7e42e19",
   "metadata": {},
   "source": [
    "### 서포트 벡터 머신 (Support Vector Machine) - 하이퍼 파라미터 찾기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03156228",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "estimator = SVC(probability=True)\n",
    "\n",
    "param_grid = {'kernel':['rbf'], 'C':[1,100,10,0.1,0.01,0.001]}\n",
    "#param_grid = [ \n",
    "#  {'kernel':['linear'], 'C':[1,100,10,0.1,0.01,0.001]}, #특정 하이퍼 파라메타 조합 피하기\n",
    "#  {'kernel':['poly','rbf'], 'C':[1,100,10,0.1,0.01,0.001], 'gamma':['auto','scale',1000,100,10,1,0.1,0.01,0.001,0.0001]}\n",
    "#]\n",
    "\n",
    "grid = GridSearchCV(estimator, param_grid=param_grid) \n",
    "#grid = GridSearchCV(estimator, param_grid=param_grid, cv=3, scoring='accuracy') #디폴트로 cv=3, 분류에서 디폴트로 scoring='accuracy'\n",
    "\n",
    "grid.fit(X_train_clf, y_train_clf)\n",
    "\n",
    "print(grid.best_score_)\n",
    "print(grid.best_params_)\n",
    "df = pd.DataFrame(grid.cv_results_)\n",
    "print(df)\n",
    "#print(df.sort_values(by='param_C'))\n",
    "#print(df.sort_values(by='param_C', ascending=0))\n",
    "#print(df.sort_values(by='rank_test_score'))\n",
    "\n",
    "estimator = grid.best_estimator_\n",
    "'''\n",
    "#estimator = SVC(**grid.best_params_)\n",
    "estimator = SVC()\n",
    "estimator.set_params(**grid.best_params_)\n",
    "\n",
    "estimator.fit(x_data, y_data)\n",
    "'''\n",
    "\n",
    "y_pred = estimator.decision_function(X_train_clf)[:2]\n",
    "y_prob = estimator.predict_proba(X_train_clf[:2]) #predict_proba is not available when  probability=False\n",
    "y_predict = estimator.predict(X_train_clf[:2])\n",
    "print(y_prob, '\\n', y_pred, '\\n', y_predict)\n",
    "\n",
    "score = grid.score(X_test_clf, y_test_clf)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72a15294",
   "metadata": {},
   "source": [
    "### 서포트 벡터 머신 (Support Vector Machine) - 회귀 - 하이퍼 파라미터 찾기\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38e761e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVR\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "estimator = SVR()\n",
    "\n",
    "param_grid = {'kernel':['rbf'], 'C':[1,100,10,0.1,0.01,0.001]}\n",
    "'''\n",
    "param_grid = [ \n",
    "  {'kernel':['linear'], 'C':[1,100,10,0.1,0.01,0.001]}, #특정 하이퍼 파라메타 조합 피하기\n",
    "  {'kernel':['poly','rbf'], 'C':[1,100,10,0.1,0.01,0.001], 'gamma':['auto','scale',1000,100,10,1,0.1,0.01,0.001,0.0001]}\n",
    "]\n",
    "'''\n",
    "\n",
    "grid = GridSearchCV(estimator, param_grid=param_grid) \n",
    "#grid = GridSearchCV(estimator, param_grid=param_grid, cv=3, scoring='r2') #디폴트로 cv=3, 회귀에서 디폴트로 scoring='r2'\n",
    "\n",
    "grid.fit(X_train_reg, y_train_reg)\n",
    "\n",
    "print(grid.best_score_)\n",
    "print(grid.best_params_)\n",
    "df = pd.DataFrame(grid.cv_results_)\n",
    "print(df)\n",
    "#print(df.sort_values(by='param_n_neighbors'))\n",
    "#print(df.sort_values(by='param_n_neighbors', ascending=0))\n",
    "#print(df.sort_values(by='rank_test_score'))\n",
    "\n",
    "estimator = grid.best_estimator_\n",
    "'''\n",
    "#estimator = SVR(**grid.best_params_)\n",
    "estimator = SVR()\n",
    "estimator.set_params(**grid.best_params_)\n",
    "\n",
    "estimator.fit(x_data, y_data)\n",
    "'''\n",
    "\n",
    "y_pred = estimator.predict(X_train_reg[:2])\n",
    "print(y_pred)\n",
    "\n",
    "score = grid.score(X_test_reg, y_test_reg)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88626228",
   "metadata": {},
   "source": [
    "### 의사 결정 나무 (Decision Tree) - 하이퍼 파라미터 찾기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ea831e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "estimator = DecisionTreeClassifier()\n",
    "\n",
    "#param_grid = {'criterion':['gini'], 'max_depth':[None,2,3,4,5,6]}\n",
    "param_grid = {'criterion':['gini','entropy'], 'max_depth':[None,2,3,4,5,6], 'max_leaf_nodes':[None,2,3,4,5,6,7], 'min_samples_split':[2,3,4,5,6], 'min_samples_leaf':[1,2,3], 'max_features':[None,'sqrt','log2',3,4,5]}\n",
    "\n",
    "grid = GridSearchCV(estimator, param_grid=param_grid) \n",
    "#grid = GridSearchCV(estimator, param_grid=param_grid, cv=3, scoring='accuracy') #디폴트로 cv=3, 분류에서 디폴트로 scoring='accuracy'\n",
    "\n",
    "grid.fit(X_train_clf, y_train_clf)\n",
    "\n",
    "print(grid.best_score_)\n",
    "print(grid.best_params_)\n",
    "df = pd.DataFrame(grid.cv_results_)\n",
    "print(df)\n",
    "#print(df.sort_values(by='param_max_depth'))\n",
    "#print(df.sort_values(by='param_max_depth', ascending=0))\n",
    "#print(df.sort_values(by='rank_test_score'))\n",
    "\n",
    "estimator = grid.best_estimator_\n",
    "'''\n",
    "#estimator = DecisionTreeClassifier(**grid.best_params_)\n",
    "estimator = DecisionTreeClassifier()\n",
    "estimator.set_params(**grid.best_params_)\n",
    "\n",
    "estimator.fit(x_data, y_data)\n",
    "'''\n",
    "\n",
    "# y_pred = estimator.decision_function(X_train_clf)[:2]\n",
    "y_prob = estimator.predict_proba(X_train_clf[:2]) #predict_proba is not available when  probability=False\n",
    "y_predict = estimator.predict(X_train_clf[:2])\n",
    "print(y_prob, '\\n', y_predict)\n",
    "\n",
    "score = grid.score(X_test_clf, y_test_clf)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb0f9714",
   "metadata": {},
   "source": [
    "### 의사 결정 나무 (Decision Tree) - 회귀 - 하이퍼 파라미터 찾기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc29bfa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "estimator = DecisionTreeRegressor()\n",
    "\n",
    "param_grid = {'criterion':['mse'], 'max_depth':[None,2,3,4,5,6]}\n",
    "#param_grid = {'criterion':['mse','friedman_mse','mae'], 'max_depth':[None,2,3,4,5,6], 'max_leaf_nodes':[None,2,3,4,5,6,7], 'min_samples_split':[2,3,4,5,6], 'min_samples_leaf':[1,2,3], max_features:[None,'sqrt','log2',3,4,5]}\n",
    "\n",
    "grid = GridSearchCV(estimator, param_grid=param_grid) \n",
    "#grid = GridSearchCV(estimator, param_grid=param_grid, cv=3, scoring='r2') #디폴트로 cv=3, 회귀에서 디폴트로 scoring='r2'\n",
    "\n",
    "grid.fit(X_train_reg, y_train_reg)\n",
    "\n",
    "print(grid.best_score_)\n",
    "print(grid.best_params_)\n",
    "df = pd.DataFrame(grid.cv_results_)\n",
    "print(df)\n",
    "#print(df.sort_values(by='param_max_depth'))\n",
    "#print(df.sort_values(by='param_max_depth', ascending=0))\n",
    "#print(df.sort_values(by='rank_test_score'))\n",
    "\n",
    "estimator = grid.best_estimator_\n",
    "'''\n",
    "#estimator = KNeighborsRegressor(**grid.best_params_)\n",
    "estimator = KNeighborsRegressor()\n",
    "estimator.set_params(**grid.best_params_)\n",
    "\n",
    "estimator.fit(x_train, y_train)\n",
    "'''\n",
    "\n",
    "y_pred = estimator.predict(X_train_reg[:2])\n",
    "print(y_pred)\n",
    "\n",
    "score = grid.score(X_test_reg, y_test_reg)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "625abdf9",
   "metadata": {},
   "source": [
    "### 앙상블 배깅 - 하이퍼 파라미터 찾기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b671ae32",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "base_estimator = DecisionTreeClassifier()\n",
    "estimator = BaggingClassifier(base_estimator=base_estimator)\n",
    "\n",
    "#'''\n",
    "param_grid = {'n_estimators':[10,1,2,3,4,5,6,7,8,9]}\n",
    "#'''\n",
    "'''\n",
    "param_grid = {\n",
    "    'n_estimators':[10,1,2,3,4,5,6,7,8,9], \n",
    "    'bootstrap':[True,False],\n",
    "    'base_estimator__criterion':['gini','entropy'], 'base_estimator__max_depth':[None,2,3,4,5,6], 'base_estimator__max_leaf_nodes':[None,2,3,4,5,6,7], 'base_estimator__min_samples_split':[2,3,4,5,6], 'base_estimator__min_samples_leaf':[1,2,3], 'base_estimator__max_features':[None,'sqrt','log2',5,6,7,8,9,10]\n",
    "}\n",
    "'''\n",
    "\n",
    "grid = GridSearchCV(estimator, param_grid=param_grid) \n",
    "#grid = GridSearchCV(estimator, param_grid=param_grid, cv=3, scoring='accuracy') #디폴트로 cv=3, 분류에서 디폴트로 scoring='accuracy'\n",
    "\n",
    "grid.fit(X_train_clf, y_train_clf)\n",
    "\n",
    "print(grid.best_score_)\n",
    "print(grid.best_params_)\n",
    "df = pd.DataFrame(grid.cv_results_)\n",
    "print(df)\n",
    "#print(df.sort_values(by='param_n_estimators'))\n",
    "#print(df.sort_values(by='param_n_estimators', ascending=0))\n",
    "#print(df.sort_values(by='rank_test_score'))\n",
    "\n",
    "estimator = grid.best_estimator_\n",
    "'''\n",
    "#estimator = BaggingClassifier(base_estimator=base_estimator, **grid.best_params_)\n",
    "estimator = BaggingClassifier(base_estimator=base_estimator)\n",
    "estimator.set_params(**grid.best_params_)\n",
    "\n",
    "estimator.fit(x_data, y_data)\n",
    "'''\n",
    "\n",
    "# y_pred = estimator.decision_function(X_train_clf)[:2]\n",
    "y_prob = estimator.predict_proba(X_train_clf[:2]) #predict_proba is not available when  probability=False\n",
    "y_predict = estimator.predict(X_train_clf[:2])\n",
    "print(y_prob, '\\n', y_predict)\n",
    "\n",
    "score = grid.score(X_test_clf, y_test_clf)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8aa4bd0",
   "metadata": {},
   "source": [
    "### 앙상블 부스팅 - 그레디언트 부스팅 - 하이퍼 파라미터 찾기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e839f630",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier \n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "estimator = GradientBoostingClassifier()\n",
    "\n",
    "param_grid = {'n_estimators':[100,90,91,92,93,94,95,96,97,98,99]}\n",
    "#param_grid = {'n_estimators':[100,90,91,92,93,94,95,96,97,98,99], 'criterion':['friedman_mse','mse','mae'], 'max_depth':[3,4,5,6], 'max_leaf_nodes':[None,2,3,4,5,6,7], 'min_samples_split':[2,3,4,5,6], 'min_samples_leaf':[1,2,3], 'max_features':[None,'sqrt','log2',5,6,7,8,9,10]}\n",
    "\n",
    "grid = GridSearchCV(estimator, param_grid=param_grid) \n",
    "#grid = GridSearchCV(estimator, param_grid=param_grid, cv=3, scoring='accuracy') #디폴트로 cv=3, 분류에서 디폴트로 scoring='accuracy'\n",
    "\n",
    "grid.fit(X_train_clf, y_train_clf)\n",
    "\n",
    "print(grid.best_score_)\n",
    "print(grid.best_params_)\n",
    "df = pd.DataFrame(grid.cv_results_)\n",
    "print(df)\n",
    "#print(df.sort_values(by='param_alpha'))\n",
    "#print(df.sort_values(by='param_alpha', ascending=0))\n",
    "#print(df.sort_values(by='rank_test_score'))\n",
    "\n",
    "estimator = grid.best_estimator_\n",
    "'''\n",
    "#estimator = GradientBoostingClassifier(**grid.best_params_)\n",
    "estimator = GradientBoostingClassifier()\n",
    "estimator.set_params(**grid.best_params_)\n",
    "\n",
    "estimator.fit(x_data, y_data)\n",
    "'''\n",
    "\n",
    "# y_pred = estimator.decision_function(X_train_clf)[:2]\n",
    "y_prob = estimator.predict_proba(X_train_clf[:2]) #predict_proba is not available when  probability=False\n",
    "y_predict = estimator.predict(X_train_clf[:2])\n",
    "print(y_prob, '\\n', y_predict)\n",
    "\n",
    "score = grid.score(X_test_clf, y_test_clf)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f983cd3",
   "metadata": {},
   "source": [
    "### 앙상블 부스팅 - 하이퍼 파라미터 찾기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ea20de2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "base_estimator = DecisionTreeClassifier()\n",
    "estimator = AdaBoostClassifier(base_estimator=base_estimator)\n",
    "\n",
    "param_grid = {'n_estimators':[10,1,2,3,4,5,6,7,8,9]}\n",
    "'''\n",
    "param_grid = {\n",
    "    'n_estimators':[10,1,2,3,4,5,6,7,8,9], \n",
    "    'base_estimator__criterion':['gini','entropy'], 'base_estimator__max_depth':[None,2,3,4,5,6], 'base_estimator__max_leaf_nodes':[None,2,3,4,5,6,7], 'base_estimator__max_features':[None,1], 'base_estimator__min_samples_split':[2,3,4,5,6], 'base_estimator__min_samples_leaf':[1,2,3], 'base_estimator__max_features':[None,'sqrt','log2',5,6,7,8,9,10]\n",
    "}\n",
    "'''\n",
    "\n",
    "grid = GridSearchCV(estimator, param_grid=param_grid) \n",
    "#grid = GridSearchCV(estimator, param_grid=param_grid, cv=3, scoring='accuracy') #디폴트로 cv=3, 분류에서 디폴트로 scoring='accuracy'\n",
    "\n",
    "grid.fit(X_train_clf, y_train_clf)\n",
    "\n",
    "print(grid.best_score_)\n",
    "print(grid.best_params_)\n",
    "df = pd.DataFrame(grid.cv_results_)\n",
    "print(df)\n",
    "#print(df.sort_values(by='param_n_estimators'))\n",
    "#print(df.sort_values(by='param_n_estimators', ascending=0))\n",
    "#print(df.sort_values(by='rank_test_score'))\n",
    "\n",
    "estimator = grid.best_estimator_\n",
    "'''\n",
    "#estimator = AdaBoostClassifier(base_estimator=base_estimator, **grid.best_params_)\n",
    "estimator = AdaBoostClassifier(base_estimator=base_estimator)\n",
    "estimator.set_params(**grid.best_params_)\n",
    "\n",
    "estimator.fit(x_data, y_data)\n",
    "'''\n",
    "\n",
    "# y_pred = estimator.decision_function(X_train_clf)[:2]\n",
    "y_prob = estimator.predict_proba(X_train_clf[:2]) #predict_proba is not available when  probability=False\n",
    "y_predict = estimator.predict(X_train_clf[:2])\n",
    "print(y_prob, '\\n', y_predict)\n",
    "\n",
    "score = grid.score(X_test_clf, y_test_clf)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "085084df",
   "metadata": {},
   "source": [
    "### 앙상블 배깅 - 랜덤 포레스트 - 하이퍼 파라미터 찾기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dc88622",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "estimator = RandomForestClassifier()\n",
    "\n",
    "param_grid = {'n_estimators':[10,1,2,3,4,5,6,7,8,9]}\n",
    "#param_grid = {'n_estimators':[10,1,2,3,4,5,6,7,8,9], 'bootstrap':[True,False], 'criterion':['gini','entropy'], 'max_depth':[None,2,3,4,5,6], 'max_leaf_nodes':[None,2,3,4,5,6,7], 'min_samples_split':[2,3,4,5,6], 'min_samples_leaf':[1,2,3], 'max_features':[None,'sqrt','log2',5,6,7,8,9,10]}\n",
    "\n",
    "grid = GridSearchCV(estimator, param_grid=param_grid) \n",
    "#grid = GridSearchCV(estimator, param_grid=param_grid, cv=3, scoring='accuracy') #디폴트로 cv=3, 분류에서 디폴트로 scoring='accuracy'\n",
    "\n",
    "grid.fit(X_train_clf, y_train_clf)\n",
    "\n",
    "print(grid.best_score_)\n",
    "print(grid.best_params_)\n",
    "df = pd.DataFrame(grid.cv_results_)\n",
    "print(df)\n",
    "#print(df.sort_values(by='param_n_estimators'))\n",
    "#print(df.sort_values(by='param_n_estimators', ascending=0))\n",
    "#print(df.sort_values(by='rank_test_score'))\n",
    "\n",
    "#'''\n",
    "estimator = grid.best_estimator_\n",
    "#'''\n",
    "'''\n",
    "#estimator = RandomForestClassifier(**grid.best_params_)\n",
    "estimator = RandomForestClassifier()\n",
    "estimator.set_params(**grid.best_params_)\n",
    "\n",
    "estimator.fit(x_data, y_data)\n",
    "'''\n",
    "\n",
    "# y_pred = estimator.decision_function(X_train_clf)[:2]\n",
    "y_prob = estimator.predict_proba(X_train_clf[:2]) #predict_proba is not available when  probability=False\n",
    "y_predict = estimator.predict(X_train_clf[:2])\n",
    "print(y_prob, '\\n', y_predict)\n",
    "\n",
    "score = grid.score(X_test_clf, y_test_clf)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1731342f",
   "metadata": {},
   "source": [
    "### 앙상블 다수결 투표 - 하이퍼 파라미터 찾기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44c3722d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn import metrics\n",
    "\n",
    "estimator = VotingClassifier(estimators=[('lr', LogisticRegression()),\n",
    "                                         ('kn', KNeighborsClassifier()),\n",
    "                                         ('dt', DecisionTreeClassifier())])\n",
    "\n",
    "param_grid = {'voting':['hard','soft']}\n",
    "'''\n",
    "param_grid = {\n",
    "  'voting':['hard','soft'], \n",
    "  'weights':[[2,1,1],[1,2,1]],\n",
    "    'kn__n_neighbors':[5,1,2,3,4], 'kn__metric':['minkowski','manhattan','euclidean'], 'kn__weights':['uniform','distance'],\n",
    "    'dt__criterion':['gini','entropy'], 'dt__max_depth':[None,2,3,4,5,6], 'dt__max_leaf_nodes':[None,2,3,4,5,6,7], 'dt__max_features':[None,1], 'dt__min_samples_split':[2,3,4,5,6], 'dt__min_samples_leaf':[1,2,3]\n",
    "}\n",
    "'''\n",
    "\n",
    "grid = GridSearchCV(estimator, param_grid=param_grid) \n",
    "#grid = GridSearchCV(estimator, param_grid=param_grid, cv=3, scoring='accuracy') #디폴트로 cv=3, 분류에서 디폴트로 scoring='accuracy'\n",
    "\n",
    "grid.fit(X_train_clf, y_train_clf)\n",
    "\n",
    "print(grid.best_score_)\n",
    "print(grid.best_params_)\n",
    "df = pd.DataFrame(grid.cv_results_)\n",
    "print(df)\n",
    "#print(df.sort_values(by='param_voting'))\n",
    "#print(df.sort_values(by='param_voting', ascending=0))\n",
    "#print(df.sort_values(by='rank_test_score'))\n",
    "\n",
    "estimator = grid.best_estimator_\n",
    "'''\n",
    "estimator = VotingClassifier(estimators=[('lr', LogisticRegression()),\n",
    "                                         ('kn', KNeighborsClassifier()),\n",
    "                                         ('dt', DecisionTreeClassifier())])\n",
    "estimator.set_params(**grid.best_params_)\n",
    "\n",
    "estimator.fit(x_data, y_data)\n",
    "'''\n",
    "\n",
    "# y_pred = estimator.decision_function(X_train_clf)[:2]\n",
    "# y_prob = estimator.predict_proba(X_train_clf[:2]) #predict_proba is not available when  probability=False\n",
    "y_predict = estimator.predict(X_train_clf[:2])\n",
    "print(y_predict)\n",
    "\n",
    "score = grid.score(X_test_clf, y_test_clf)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32d89f08",
   "metadata": {},
   "source": [
    "### 앙상블 배깅 - 회귀 - 하이퍼 파라미터 찾기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62810a21",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import BaggingRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "base_estimator = DecisionTreeRegressor()\n",
    "estimator = BaggingRegressor(base_estimator=base_estimator)\n",
    "\n",
    "param_grid = {'n_estimators':[10,1,2,3,4,5,6,7,8,9]}\n",
    "'''\n",
    "param_grid = {\n",
    "    'n_estimators':[10,1,2,3,4,5,6,7,8,9],\n",
    "    'bootstrap':[True,False],\n",
    "    'base_estimator__criterion':['gini','entropy'], 'base_estimator__max_depth':[None,2,3,4,5,6], 'base_estimator__max_leaf_nodes':[None,2,3,4,5,6,7], 'base_estimator__min_samples_split':[2,3,4,5,6], 'base_estimator__min_samples_leaf':[1,2,3], 'base_estimator__max_features':[None,'sqrt','log2',5,6,7,8,9,10]\n",
    "}\n",
    "'''\n",
    "\n",
    "grid = GridSearchCV(estimator, param_grid=param_grid) \n",
    "#grid = GridSearchCV(estimator, param_grid=param_grid, cv=3, scoring='accuracy') #디폴트로 cv=3, 분류에서 디폴트로 scoring='accuracy'\n",
    "\n",
    "grid.fit(X_train_reg, y_train_reg)\n",
    "\n",
    "print(grid.best_score_)\n",
    "print(grid.best_params_)\n",
    "df = pd.DataFrame(grid.cv_results_)\n",
    "print(df)\n",
    "#print(df.sort_values(by='param_n_estimators'))\n",
    "#print(df.sort_values(by='param_n_estimators', ascending=0))\n",
    "#print(df.sort_values(by='rank_test_score'))\n",
    "\n",
    "estimator = grid.best_estimator_\n",
    "'''\n",
    "#estimator = BaggingRegressor(base_estimator=base_estimator, **grid.best_params_)\n",
    "estimator = BaggingRegressor(base_estimator=base_estimator)\n",
    "estimator.set_params(**grid.best_params_)\n",
    "\n",
    "estimator.fit(x_data, y_data)\n",
    "'''\n",
    "\n",
    "y_pred = estimator.predict(X_train_reg[:2])\n",
    "print(y_pred)\n",
    "\n",
    "score = grid.score(X_test_reg, y_test_reg)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0d8ffa7",
   "metadata": {},
   "source": [
    "### 앙상블 배깅 - 랜덤 포레스트 - 회귀 - 하이퍼 파라미터 찾기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4b8a9d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor \n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "estimator = RandomForestRegressor()\n",
    "\n",
    "param_grid = {'n_estimators':[10,1,2,3,4,5,6,7,8,9]}\n",
    "#param_grid = {'n_estimators':[10,1,2,3,4,5,6,7,8,9], 'bootstrap':[True,False], 'criterion':['mse','friedman_mse','mae'], 'max_depth':[None,2,3,4,5,6], 'max_leaf_nodes':[None,2,3,4,5,6,7], 'min_samples_split':[2,3,4,5,6], 'min_samples_leaf':[1,2,3], 'max_features':[None,'sqrt','log2',5,6,7,8,9,10]}\n",
    "\n",
    "grid = GridSearchCV(estimator, param_grid=param_grid) \n",
    "#grid = GridSearchCV(estimator, param_grid=param_grid, cv=3, scoring='accuracy') #디폴트로 cv=3, 분류에서 디폴트로 scoring='accuracy'\n",
    "\n",
    "grid.fit(X_train_reg, y_train_reg)\n",
    "\n",
    "print(grid.best_score_)\n",
    "print(grid.best_params_)\n",
    "df = pd.DataFrame(grid.cv_results_)\n",
    "print(df)\n",
    "#print(df.sort_values(by='param_n_estimators'))\n",
    "#print(df.sort_values(by='param_n_estimators', ascending=0))\n",
    "#print(df.sort_values(by='rank_test_score'))\n",
    "\n",
    "estimator = grid.best_estimator_\n",
    "'''\n",
    "#estimator = RandomForestRegressor(**grid.best_params_)\n",
    "estimator = RandomForestRegressor()\n",
    "estimator.set_params(**grid.best_params_)\n",
    "\n",
    "estimator.fit(x_data, y_data)\n",
    "'''\n",
    "\n",
    "y_pred = estimator.predict(X_train_reg[:2])\n",
    "print(y_pred)\n",
    "\n",
    "score = grid.score(X_test_reg, y_test_reg)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "141a1f32",
   "metadata": {},
   "source": [
    "### 앙상블 부스팅 - 그레디언트 부스팅 - 회귀 - 하이퍼 파라미터 찾기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62f481a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor \n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "estimator = GradientBoostingRegressor()\n",
    "\n",
    "param_grid = {'n_estimators':[100,90,91,92,93,94,95,96,97,98,99]}\n",
    "#param_grid = {'n_estimators':[100,90,91,92,93,94,95,96,97,98,99], 'criterion':['friedman_mse','mse','mae'], 'max_depth':[3,4,5,6], 'max_leaf_nodes':[None,2,3,4,5,6,7], 'min_samples_split':[2,3,4,5,6], 'min_samples_leaf':[1,2,3], max_features:[None,'sqrt','log2',5,6,7,8,9,10]}\n",
    "\n",
    "grid = GridSearchCV(estimator, param_grid=param_grid) \n",
    "#grid = GridSearchCV(estimator, param_grid=param_grid, cv=3, scoring='accuracy') #디폴트로 cv=3, 분류에서 디폴트로 scoring='accuracy'\n",
    "\n",
    "grid.fit(X_train_reg, y_train_reg)\n",
    "\n",
    "print(grid.best_score_)\n",
    "print(grid.best_params_)\n",
    "df = pd.DataFrame(grid.cv_results_)\n",
    "print(df)\n",
    "#print(df.sort_values(by='param_n_estimators'))\n",
    "#print(df.sort_values(by='param_n_estimators', ascending=0))\n",
    "#print(df.sort_values(by='rank_test_score'))\n",
    "\n",
    "estimator = grid.best_estimator_\n",
    "'''\n",
    "#estimator = GradientBoostingRegressor(**grid.best_params_)\n",
    "estimator = GradientBoostingRegressor()\n",
    "estimator.set_params(**grid.best_params_)\n",
    "\n",
    "estimator.fit(x_data, y_data)\n",
    "'''\n",
    "\n",
    "y_pred = estimator.predict(X_train_reg[:2])\n",
    "print(y_pred)\n",
    "\n",
    "score = grid.score(X_test_reg, y_test_reg)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d86ad866",
   "metadata": {},
   "source": [
    "### 앙상블 부스팅 - 회귀 - 하이퍼 파라미터 찾기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcff73b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "base_estimator = DecisionTreeRegressor()\n",
    "estimator = AdaBoostRegressor(base_estimator=base_estimator)\n",
    "\n",
    "param_grid = {'n_estimators':[10,1,2,3,4,5,6,7,8,9]}\n",
    "'''\n",
    "param_grid = {\n",
    "    'n_estimators':[10,1,2,3,4,5,6,7,8,9], \n",
    "    'base_estimator__criterion':['gini','entropy'], 'base_estimator__max_depth':[None,2,3,4,5,6], 'base_estimator__max_leaf_nodes':[None,2,3,4,5,6,7], 'base_estimator__min_samples_split':[2,3,4,5,6], 'base_estimator__min_samples_leaf':[1,2,3], 'base_estimator__max_features':[None,'sqrt','log2',5,6,7,8,9,10]\n",
    "}\n",
    "'''\n",
    "\n",
    "grid = GridSearchCV(estimator, param_grid=param_grid) \n",
    "#grid = GridSearchCV(estimator, param_grid=param_grid, cv=3, scoring='accuracy') #디폴트로 cv=3, 분류에서 디폴트로 scoring='accuracy'\n",
    "\n",
    "grid.fit(X_train_reg, y_train_reg)\n",
    "\n",
    "print(grid.best_score_)\n",
    "print(grid.best_params_)\n",
    "df = pd.DataFrame(grid.cv_results_)\n",
    "print(df)\n",
    "#print(df.sort_values(by='param_n_estimators'))\n",
    "#print(df.sort_values(by='param_n_estimators', ascending=0))\n",
    "#print(df.sort_values(by='rank_test_score'))\n",
    "\n",
    "estimator = grid.best_estimator_\n",
    "'''\n",
    "#estimator = AdaBoostRegressor(base_estimator=base_estimator, **grid.best_params_)\n",
    "estimator = AdaBoostRegressor()\n",
    "estimator.set_params(**grid.best_params_)\n",
    "\n",
    "estimator.fit(x_data, y_data)\n",
    "'''\n",
    "\n",
    "y_pred = estimator.predict(X_train_reg[:2])\n",
    "print(y_pred)\n",
    "\n",
    "score = grid.score(X_test_reg, y_test_reg)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03b961cf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
